# Масштабирование решений, основанных на контейнерах
Следующие четыре термина имеют отношение к одновременному использованию нескольких контейнеров.

### Сеть Docker
![](https://habrastorage.org/r/w1560/getpro/habr/post_images/d45/36a/490/d4536a49030b09ebbe0adb09ec4e0598.png)

Сетевые механизмы Docker ([Docker Networking](https://docs.docker.com/engine/tutorials/networkingcontainers/)) позволяют организовывать связь между контейнерами Docker. Соединённые с помощью сети контейнеры могут выполняться на одном и том же хосте или на разных хостах. Подробности о сетевой подсистеме Docker можно почитать [здесь](https://www.oreilly.com/content/what-is-docker-networking/).

### Docker Compose
[Docker Compose](https://docs.docker.com/compose/) — это инструмент, который упрощает развёртывание приложений, для работы которых требуется несколько контейнеров Docker. Docker Compose позволяет выполнять команды, описываемые в файле ```docker-compose.yml```. Эти команды можно выполнять столько раз, сколько потребуется. Интерфейс командной строки Docker Compose упрощает взаимодействие с многоконтейнерными приложениями. Этот инструмент устанавливается при установке Docker.

### Docker Swarm
[Docker Swarm](https://docs.docker.com/engine/swarm/) — это решение, предназначенное для управления контейнерными развёртываниями (то есть, как говорят, для оркестрации контейнеров).

### Сервисы Docker
[Сервисы](https://docs.docker.com/get-started/04_sharing_app/#introduction) — это всего лишь «контейнеры в продакшне». В пределах сервиса выполняется лишь один образ, но сервис определяет то, как именно выполняется образ. В частности, речь идёт о том, какие порты должны использоваться, сколько реплик контейнера должно выполняться для того, чтобы сервис обеспечивал бы необходимую вычислительную мощность, и так далее. Масштабирование сервисов предусматривает изменение количества экземпляров контейнера, в которых работает некая программа, благодаря чему сервису выделяется столько системных ресурсов, сколько ему требуется для решения некоей задачи.

Сервисы Docker позволяют масштабировать контейнеры в пределах нескольких демонов Docker, благодаря им существует и технология Docker Swarm.
 
# Уменьшение размеров образов и ускорение их сборки
**Приемы оптимизации сборки Docker-образов:**
* уменьшение количества слоев в образе
* удаление ненужный кэш apt-get
* копирование только нужных файлов проекта в образ с помощью ```.dockerignore```-файла
* использование минималистического Linux-образа Alpine
* часто изменяемые слои в конец Dockerfile. 
  _Если вы собираетесь вносить изменения в инструкции Dockerfile, тогда каждый слой, созданный инструкциями, идущими после изменённых, будет достаточно часто собираться повторно, без использования кэша. Для того чтобы воспользоваться преимуществами кэширования, помещайте инструкции, вероятность изменения которых высока, как можно ближе к концу Dockerfile._

**Рекомендации:**
* Используйте всегда, когда это возможно, официальные образы в качестве базовых образов. Официальные образы регулярно обновляются, они безопаснее неофициальных образов.
* Объединяйте команды ```RUN apt-get update``` и ```apt-get install``` в цепочки для того, чтобы исключить проблемы, связанные с неправильным использованием кэша. Перечисляйте пакеты в алфавитном порядке на нескольких строках, разделяя список символами ```\```. Например, это может выглядеть так:
    ```
    RUN apt-get update && apt-get install -y \
        package-one \
        package-two \
        package-three
    && rm -rf /var/lib/apt/lists/*
    ```
    Этот метод позволяет сократить число слоёв, которые должны быть добавлены в образ, и помогает поддерживать код файла в приличном виде.

* Взгляните на [dive](https://github.com/wagoodman/dive) — отличный инструмент для исследования образов Docker, который помогает в деле уменьшения их размеров.
* Не устанавливайте в образы пакеты, без которых можно обойтись.

### Кэширование

Одной из сильных сторон Docker является кэширование. Благодаря этому механизму ускоряется сборка образов.

При сборке образа Docker проходится по инструкциям файла Dockerfile, выполняя их по порядку. В процессе анализа инструкций Docker проверяет собственный кэш на наличие в нём образов, представляющих собой то, что получается на промежуточных этапах сборки других образов. Если подобные образы удаётся найти, то система может ими воспользоваться, не тратя время на их повторное создание.

Если кэш признан недействительным, то инструкция, в ходе выполнения которой это произошло, выполняется, создавая новый слой без использования кэша. То же самое происходит и при выполнении инструкций, которые следуют за ней.

Использование кэша способно ускорить сборку образов, но тут есть одна проблема. Например, если в Dockerfile обнаруживается инструкция ```RUN pip install -r requirements.txt```, то Docker выполняет поиск такой же инструкции в своём локальном кэше промежуточных образов. При этом содержимое старой и новой версий файла ```requirements.txt``` не сравнивается.

Подобное может приводить к проблемам в том случае, если в ```requirements.txt``` были добавлены сведения о новых пакетах, после чего, при сборке обновлённого образа, для того, чтобы установить новый набор пакетов, нужно снова выполнить инструкцию ```RUN pip install```. Совсем скоро мы поговорим о том, как бороться с этой проблемой.

В отличие от других инструкций Docker, при выполнении инструкций ```ADD``` и ```COPY``` от Docker требуется проверка содержимого файла или файлов для определения того, можно ли, при формировании образа, воспользоваться кэшем. А именно, контрольная сумма файлов, упомянутых в этих инструкциях, сравнивается с контрольной суммой файлов, которые имеются в промежуточных образах, которые уже есть в кэше. Если изменилось содержимое файлов или их метаданные, тогда кэш признаётся недействительным.

_Вот несколько советов, касающихся эффективного использования кэша Docker:_

* Кэширование можно отключить, передав ключ --no-cache=True команде docker build.
* Если вы используете менеджеры пакетов, наподобие ```pip```, с файлом ```requirements.txt```, тогда придерживайтесь нижеприведённой схемы работы для того, чтобы исключить использование устаревших промежуточных образов из кэша, содержащих набор пакетов, перечисленных в старой версии файла ```requirements.txt```. Вот как это выглядит:
    ```
    COPY requirements.txt /tmp/
    RUN pip install -r /tmp/requirements.txt
    COPY . /tmp/
    ```

### Файл .dockerignore

О файлах ```.dockerignore``` нужно знать абсолютно всем, кто хочет освоить Docker. Эти файлы похожи на файлы ```.gitignore```. Они содержат список файлов и папок, в виде имён или шаблонов, которые Docker должен игнорировать в ходе сборки образа.

Этот файл размещают там же, где находится файл Dockerfile, и всё остальное, входящее в контекст сборки образа.

При запуске команды ```docker build```, инициирующей сборку образа, Docker проверяет папку на наличие в ней файла ```.dockerignore```. Если такой файл найти удаётся, тогда этот файл разбирается, при этом при определении списка файлов, которые нужно игнорировать, используются [правила](https://pkg.go.dev/path/filepath#Match) функции Match() из пакета filepath Go и некоторые собственные [правила](https://docs.docker.com/engine/reference/builder/#dockerignore-file) Docker.

Так, например, если в файле ```.dockerignore``` встретится шаблон вида ```*.jpg```, то при создании образа проигнорированы будут файлы с любым именем и с расширением ```.jpg```. Если в файле встретится строка ```videos```, то система проигнорирует папку ```videos``` и всё её содержимое.

При составлении файла ```.dockerignore``` его можно снабжать комментариями, используя символ ```#```.

Вот что даёт тому, кто занимается созданием образов Docker, применение файлов ```.dockerignore```:
* Это позволяет исключать из состава образа файлы, содержащие секретные сведения наподобие логинов и паролей.
* Это позволяет уменьшить размер образа. Чем меньше в образе файлов — тем меньше будет его размер и тем быстрее с ним можно будет работать.
* Это даёт возможность уменьшить число поводов для признания недействительным кэша при сборке похожих образов. Например, если при повторной сборке образа меняются некие служебные файлы проекта, наподобие файлов с журналами, из-за чего данные, хранящиеся в кэше, по сути, необоснованно признаются недействительными, это замедляет сборку образов.

Подробности о файле ```.dockerignore``` можно почитать в [документации](https://docs.docker.com/engine/reference/builder/#dockerignore-file) к Docker.

### Alpine
Базовый образ Alpine представляет собой полноценный дистрибутив Linux-подобной ОС, содержащий минимум дополнительных пакетов. Его размер — примерно 5 мегабайт. Однако сборка собственного образа на основе Alpine потребует потратить достаточно много времени на то, чтобы оснастить его всем необходимым для обеспечения работы некоего приложения.

Существуют и специализированные варианты базового образа Alpine. Например, соответствующий образ из репозитория python, в который упакован скрипт print("hello world") весит около 78.5 Мб. Вот Dockerfile для сборки такого образа:
```
FROM python:3.7.2-alpine3.8
COPY . /app
ENTRYPOINT ["python", "./app/my_script.py", "my_var"]
```
При этом на Docker Hub сказано, что этот базовый образ имеет размер 29 Мб. Размер образа, основанного на этом базовом образе, увеличивается за счёт загрузки и установки Python.

# Работа с данными
_Этот материал подготовлен с использованием движка Docker версии 18.09.1 и API версии 1.39._

### Временное хранение данные
В контейнерах Docker организовать работу с временными данными можно двумя способами.

По умолчанию файлы, создаваемые приложением, работающим в контейнере, сохраняются в слое контейнера, поддерживающем запись. Для того чтобы этот механизм работал, ничего специально настраивать не нужно. Приложению достаточно просто сохранить данные и продолжить заниматься своими делами. Однако после того как контейнер перестанет существовать, исчезнут и данные.

Для хранения временных файлов в Docker можно воспользоваться ещё одним решением, подходящим для тех случаев, когда требуется более высокий уровень производительности, в сравнении с тем, который достижим при использовании стандартного механизма временного хранения данных. Если вам не нужно, чтобы ваши данные хранились бы дольше, чем существует контейнер, вы можете подключить к контейнеру tmpfs — временное хранилище информации, которое использует оперативную память хоста. Это позволит ускорить выполнение операций по записи и чтению данных.

Часто бывает так, что данные нужно хранить и после того, как контейнер прекратит существовать. Для этого нам пригодятся механизмы постоянного хранения данных.

### Постоянное хранение данных
Существуют два способа, позволяющих сделать срок жизни данных большим срока жизни контейнера. Один из способов заключается в использовании технологии bind mount. При таком подходе к контейнеру можно примонтировать, например, реально существующую папку. Работать с данными, хранящимися в такой папке, смогут и процессы, находящиеся за пределами Docker. Вот как [выглядят](https://docs.docker.com/storage/volumes/) монтирование tmpfs и технология bind mount. 
![](https://habrastorage.org/r/w1560/getpro/habr/post_images/29c/1ea/9a4/29c1ea9a4546930dd8d03c7c5f521cc8.png)
Минусы использования технологии bind mount заключаются в том, что её использование усложняет резервное копирование данных, миграцию данных, совместное использование данных несколькими контейнерами. Гораздо лучше для постоянного хранения данных использовать тома Docker.

## Тома Docker
**Том** — это файловая система, которая расположена на хост-машине за пределами контейнеров. Созданием и управлением томами занимается Docker. Вот основные свойства томов Docker:

* Они представляют собой средства для постоянного хранения информации.
* Они самостоятельны и отделены от контейнеров.
* Ими могут совместно пользоваться разные контейнеры.
* Они позволяют организовать эффективное чтение и запись данных.
* Тома можно размещать на ресурсах удалённого облачного провайдера.
* Их можно шифровать.
* Им можно давать имена.
* Контейнер может организовать заблаговременное наполнение тома данными.
* Они удобны для тестирования.

#### Создание томов

Тома можно создавать средствами Docker или с помощью запросов к API.

Вот инструкция в Dockerfile, которая позволяет создать том при запуске контейнера.
```
VOLUME /my_volume
```
При использовании подобной инструкции Docker, после создания контейнера, создаст том, содержащий данные, которые уже имеются в указанном месте. Обратите внимание на то, что если вы создаёте том с использованием Dockerfile, это не освобождает вас от необходимости указать точку монтирования тома.

Создавать тома в Dockerfile можно и используя формат JSON.

Кроме того, тома можно создавать средствами командной строки во время работы контейнера.

#### Работа с томами из командной строки
**Создание тома**

```
docker volume create —-name my_volume
```
**Выяснение информации о томах**
Для того чтобы просмотреть список томов Docker, воспользуйтесь следующей командой:
```
docker volume ls
```
Исследовать конкретный том можно так:
```
docker volume inspect my_volume
```
**Удаление тома**
```
docker volume rm my_volume
```
Для того чтобы удалить все тома, которые не используются контейнерами, можно прибегнуть к такой команде:
```
docker volume prune
```
Перед удалением томов Docker запросит у вас подтверждение выполнения этой операции.

Если том связан с каким-либо контейнером, такой том нельзя удалить до тех пор, пока не удалён соответствующий контейнер. При этом, даже если контейнер удалён, Docker не всегда это понимает. Если это случилось — можете воспользоваться следующей командой:
```
docker system prune
```
Она предназначена для очистки ресурсов Docker. После выполнения этой команды у вас должна появиться возможность удалить тома, статус которых до этого определялся неправильно.

## Полезные материалы:
[Статья на habr: работа с данными](https://habr.com/ru/company/ruvds/blog/441574/)
